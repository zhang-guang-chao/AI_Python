{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 大模型应用开发基础\n",
    "\n",
    "## 💡 这节课会带给你\n",
    "\n",
    "1. 整体了解大模型应用开发技术栈和学习方法\n",
    "2. 大模型的能力边界\n",
    "3. 搭建自己的开发环境\n",
    "4. 浅尝 OpenAI API 的调用和python的界面开发。\n",
    "\n",
    "开始上课！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、整体了解大模型应用开发技术栈和学习方法\n",
    "### 1.1、大模型应用开发技术栈\n",
    "\n",
    "在图中找到自己的地盘。\n",
    "\n",
    "<img src=\"structure.png\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2、学习方法\n",
    "\n",
    "| 学员 | 感受 | 建议 |\n",
    "| ---------- | --------------------- | ----------------------- |\n",
    "| 有明确的项目需求 | 你会感觉课程进度太慢，不能直接解决自己的问题 | 加我微信18510211925，约我1v1 |\n",
    "| 没有明确项目需求，找工作、技术提升 | 可能会有听不懂 | 别着急，一定要完成作业，不会就立刻问 |\n",
    "\n",
    "学习建议：\n",
    "\n",
    "1. 原理一定要用心学。除了 Fine-tuning 原理外，都不算难\n",
    "2. 认知一定要用心领悟。这是这门课最领先的地方\n",
    "3. 编程和工程经验不足，练！练！练！没有捷径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "## 二、大模型能干什么？\n",
    "\n",
    "大模型，全称「大语言模型」，英文「Large Language Model」，缩写「LLM」。\n",
    "\n",
    "现在，已经不需要再演示了。每人应该都至少和下面一个基于大模型的对话产品，对话过至少 100 次。\n",
    "\n",
    "| 国家 | 对话产品           | 大模型         | 链接                                                             |\n",
    "| ---- | ------------------ | -------------- | ---------------------------------------------------------------- |\n",
    "| 美国 | OpenAI ChatGPT     | GPT-3.5、GPT-4 | [https://chat.openai.com/](https://chat.openai.com/)             |\n",
    "| 美国 | Microsoft Copilot  | GPT-4 和未知   | [https://copilot.microsoft.com/](https://copilot.microsoft.com/) |\n",
    "| 美国 | Google Bard        | Gemini         | [https://bard.google.com/](https://bard.google.com/)             |\n",
    "| 中国 | 百度文心一言       | 文心 4.0       | [https://yiyan.baidu.com/](https://yiyan.baidu.com/)             |\n",
    "| 中国 | 讯飞星火           | 星火 3.5       | [https://xinghuo.xfyun.cn/](https://xinghuo.xfyun.cn/)           |\n",
    "| 中国 | 智谱清言           | GLM-4          | [https://chatglm.cn/](https://chatglm.cn/)                       |\n",
    "| 中国 | 月之暗面 Kimi Chat | Moonshot       | [https://kimi.moonshot.cn/](https://kimi.moonshot.cn/)           |\n",
    "| 中国 | MiniMax 星野       | abab6          | [https://www.xingyeai.com/](https://www.xingyeai.com/)           |\n",
    "\n",
    "本课第一个专业向要求：分清**对话产品**和**大模型**。\n",
    "\n",
    "但是，千万别以为大模型只是聊天机器人。它的能量，远不止于此。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "### 2.1、按格式输出\n",
    "\n",
    "<img src=\"./gpt-ner.jpg\" style=\"margin-left: 0px\">\n",
    "\n",
    "### 2.2、分类\n",
    "\n",
    "<img src=\"./gpt-classification.png\" style=\"margin-left: 0px\" width=600px>\n",
    "\n",
    "### 2.3、聚类\n",
    "\n",
    "<img src=\"./gpt-clustering.png\" style=\"margin-left: 0px\" width=600px>\n",
    "\n",
    "### 2.4、持续互动\n",
    "\n",
    "<img src=\"./gpt-decision.png\" style=\"margin-left: 0px\" width=600px>\n",
    "\n",
    "### 2.5、技术相关问题\n",
    "\n",
    "<img src=\"./gpt-plan.png\" style=\"margin-left: 0px\" width=600px>\n",
    "\n",
    "### 2.6、更多举例\n",
    "\n",
    "- **舆情分析：**从公司产品的评论中，分析哪些功能/元素是用户讨论最多的，评价是正向还是负向\n",
    "- **坐席质检：**检查客服/销售人员与用户的对话记录，判断是否有争吵、辱骂、不当言论，话术是否符合标准\n",
    "- **知识库：**让大模型基于私有知识回答问题\n",
    "- **零代码开发/运维：**自动规划任务，生成指令，自动执行\n",
    "- **AI 编程：**用 AI 编写代码，提升开发效率\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>思考：</b>你的业务中，有哪些问题可以用 AI 解决？\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.7、可能一切问题，都能解决，所以是 AGI（Artificial General Intelligence）\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>\n",
    "<ol>\n",
    "<li>把大模型看做是一个万能函数，给输入，<b>生成</b>输出</li>\n",
    "<li>任何问题，都可以用语言描述，成为大模型的输入，就能<b>生成</b>问题的结果</li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "这当然还是美好的理想，但正在无限逼近。我们很幸运，能亲历这个过程。\n",
    "\n",
    "当下，如何发挥大模型的现有能力呢？最大障碍是没有形成认知对齐。\n",
    "\n",
    "<img src=\"./landing.jpg\" style=\"margin-left: 0px\" width=700px>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>找落地场景的思路：</b>\n",
    "<ol>\n",
    "<li>从最熟悉的领域入手</li>\n",
    "<li>让 AI 学最厉害员工的能力，再让 ta 辅助其他员工，实现降本增效</li>\n",
    "<li>找「文本进、文本出」的场景</li>\n",
    "<li>别求大而全。将任务拆解，先解决小任务、小场景（周鸿祎：「小切口，大纵深」）</li>\n",
    "</ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、环境安装\n",
    "\n",
    "### 3.1、网络\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>建议：</b>\n",
    "<ul>\n",
    "<li>建议要有一个访问国外的「通道」，否则无法有顶级体验</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div>实在找不到【科学上网】，试试这个</div>\n",
    "\n",
    "<img src=\"./vpn-code.jpg\" style=\"margin-left: 0px\" width=500px>\n",
    "\n",
    "### 代理功能\n",
    "- 全局代理\n",
    "- 支持美国、欧洲、日本、新加坡、韩国...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2、大模型基座\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>建议：</b>\n",
    "<ul>\n",
    "<li>如果不能访问 ChatGPT，不是 ChatGPT Plus 会员，会非常遗憾</li>\n",
    "<li><a href=\"https://copilot.microsoft.com/\">Microsoft Copilot</a> 是 ChatGPT 免费平替，用的也是宇宙最强 GPT-4 大模型</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "**如何获取OpenAI APIKey**\n",
    "\n",
    "#### 注册OpenAI 账号\n",
    "- 官网注册地址：https://auth0.openai.com/u/signup/identifier?state=hKFo2SBIbkotZTNrRjI1Smp4Mm4tQUpzdHlfSzNTNHQ1VG83a6Fur3VuaXZlcnNhbC1sb2dpbqN0aWTZIDFmbjRqZklWZk9PTG9lMERkRVRnRVo2UzdtbWpEVWdxo2NpZNkgRFJpdnNubTJNdTQyVDNLT3BxZHR3QjNOWXZpSFl6d0Q\n",
    "- 注册Gmail\n",
    "- 需要国外的手机号，我们需要一个虚拟的接码平台，https://sms-activate.org/cn， 注册并且购买一个虚拟的手机号，等待接受OpenAI发送的手机验证码，填写完成注册\n",
    "\n",
    "#### 使用 OpenAI API\n",
    "- 登录后进入：https://platform.openai.com/api-keys\n",
    "- 点击 Create new secret key\n",
    "- 这个创建之后是可以使用的\n",
    "- 但是试用后会需要你关联自己的信用卡，并且这个卡要求必须是OpenAI 允许的国家的本地信用卡\n",
    "- 海外支付平台：https://www.nobepay.com/app/card-list，创建一张虚拟信用卡，并且充值，把卡信息关联到 OpenAI的账户上\n",
    "- 小Tips：关联信用卡时，网络连接最好和卡片的注册地址一致；使用浏览器的无痕窗口关联；如果不行，可以咨询下海外支付平台的客服\n",
    "- 钱不要充太多\n",
    "\n",
    "关联后就可以随心玩了，模型都可以使用。\n",
    "\n",
    "\n",
    "**如果觉得太复杂**\n",
    "\n",
    "去国内代理 https://devcto.com/ ，文档地址 https://docs.devcto.com/\n",
    "- 访问限制：解决了大陆地区用户无法直接访问OpenAI API（https://api.openai.com）的问题\n",
    "- 支付限制：针对OpenAI服务的充值需要使用国外发行银行卡的问题，DevAGI提供了解决方案，支持更多本地支付方式，简化了充值过程。\n",
    "- 价格优惠：提供的服务价格是官方标价的4折，对于价格敏感的用户来说极具吸引力，使得用户能够以更低的成本享受到AI服务。\n",
    "- 高调用速率：提供了极高的调用速率，达到每分钟最多40000次调用（如果直接使用官方，普通用户每分钟最多100次调用），满足了需要大量AI计算能力的企-业或开发者的需求。\n",
    "\n",
    "**不想花钱**\n",
    "\n",
    "使用月之暗面代替，官方控制台 https://platform.moonshot.cn/console/api-keys，\n",
    "[目前的优惠政策](https://platform.moonshot.cn/docs/pricing#%E5%85%85%E5%80%BC%E4%B8%8E%E9%99%90%E9%80%9F)\n",
    "\n",
    "- 通义\n",
    "- 文心\n",
    "- 豆包（Coze）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3、开发环境\n",
    "\n",
    "- 课上的 python 版本使用 3.8、3.9。\n",
    "- 使用 miniconda 来管理python的环境，安装教程 https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html。\n",
    "- 云端操作使用 jupyterlab，使用 `conda install jupyterlab` 来安装，启动命令 `jupyter lab --ip 0.0.0.0 --port 9090 --allow-root`\n",
    "- 本地IDE 使用 Cursor，下载地址 https://cursor.sh/\n",
    "- 腾讯tione用来做大模型微调 https://console.cloud.tencent.com/tione/v2/notebook/create?regionId=1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "## 四、大模型是怎么生成结果的？\n",
    "\n",
    "### 4.1、通俗原理\n",
    "\n",
    "其实，它只是根据上文，猜下一个词（的概率）……\n",
    "\n",
    "<img src=\"./lm-autoregressive.gif\" style=\"margin-left: 0px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "OpenAI 的接口名就叫「completion」，也证明了其只会「生成」的本质。\n",
    "\n",
    "下面用程序演示「生成下一个字」。你可以自己修改 prompt 试试。还可以使用相同的 prompt 运行多次。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /root/miniconda3/envs/aigclass\n",
      "\n",
      "  added / updated specs:\n",
      "    - openai\n",
      "    - python-dotenv\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    annotated-types-0.6.0      |   py39h06a4308_0          22 KB\n",
      "    click-8.1.7                |   py39h06a4308_0         163 KB\n",
      "    distro-1.9.0               |   py39h06a4308_0          31 KB\n",
      "    h11-0.14.0                 |   py39h06a4308_0          89 KB\n",
      "    httpcore-1.0.2             |   py39h06a4308_0          82 KB\n",
      "    httpx-0.26.0               |   py39h06a4308_0         128 KB\n",
      "    openai-1.25.0              |   py39h06a4308_0         314 KB\n",
      "    pydantic-2.5.3             |   py39h06a4308_0         532 KB\n",
      "    pydantic-core-2.14.6       |   py39hb02cf49_0         1.4 MB\n",
      "    python-dotenv-0.21.0       |   py39h06a4308_0          33 KB\n",
      "    tqdm-4.66.4                |   py39h2f386ee_0         133 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  annotated-types    pkgs/main/linux-64::annotated-types-0.6.0-py39h06a4308_0 \n",
      "  click              pkgs/main/linux-64::click-8.1.7-py39h06a4308_0 \n",
      "  distro             pkgs/main/linux-64::distro-1.9.0-py39h06a4308_0 \n",
      "  h11                pkgs/main/linux-64::h11-0.14.0-py39h06a4308_0 \n",
      "  httpcore           pkgs/main/linux-64::httpcore-1.0.2-py39h06a4308_0 \n",
      "  httpx              pkgs/main/linux-64::httpx-0.26.0-py39h06a4308_0 \n",
      "  openai             pkgs/main/linux-64::openai-1.25.0-py39h06a4308_0 \n",
      "  pydantic           pkgs/main/linux-64::pydantic-2.5.3-py39h06a4308_0 \n",
      "  pydantic-core      pkgs/main/linux-64::pydantic-core-2.14.6-py39hb02cf49_0 \n",
      "  python-dotenv      pkgs/main/linux-64::python-dotenv-0.21.0-py39h06a4308_0 \n",
      "  tqdm               pkgs/main/linux-64::tqdm-4.66.4-py39h2f386ee_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "pydantic-core-2.14.6 | 1.4 MB    |                                       |   0% \n",
      "pydantic-2.5.3       | 532 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "openai-1.25.0        | 314 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "click-8.1.7          | 163 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "tqdm-4.66.4          | 133 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "httpx-0.26.0         | 128 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "h11-0.14.0           | 89 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "httpcore-1.0.2       | 82 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-dotenv-0.21.0 | 33 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "distro-1.9.0         | 31 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "annotated-types-0.6. | 22 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pydantic-2.5.3       | 532 KB    | #1                                    |   3% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "tqdm-4.66.4          | 133 KB    | ####4                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "click-8.1.7          | 163 KB    | ###6                                  |  10% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "click-8.1.7          | 163 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "click-8.1.7          | 163 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "httpx-0.26.0         | 128 KB    | ####6                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "tqdm-4.66.4          | 133 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "tqdm-4.66.4          | 133 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pydantic-core-2.14.6 | 1.4 MB    | 4                                     |   1% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-dotenv-0.21.0 | 33 KB     | #################8                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "httpcore-1.0.2       | 82 KB     | #######2                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pydantic-core-2.14.6 | 1.4 MB    | ###2                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-dotenv-0.21.0 | 33 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python-dotenv-0.21.0 | 33 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openai-1.25.0        | 314 KB    | ##################8                   |  51% \u001b[A\u001b[A\n",
      "pydantic-2.5.3       | 532 KB    | ##################################### | 100% \u001b[A\n",
      "pydantic-2.5.3       | 532 KB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pydantic-core-2.14.6 | 1.4 MB    | ####8                                 |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "distro-1.9.0         | 31 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "h11-0.14.0           | 89 KB     | ######6                               |  18% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "httpx-0.26.0         | 128 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pydantic-core-2.14.6 | 1.4 MB    | ########1                             |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "httpcore-1.0.2       | 82 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "httpcore-1.0.2       | 82 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pydantic-core-2.14.6 | 1.4 MB    | #############                         |  35% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "h11-0.14.0           | 89 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "h11-0.14.0           | 89 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pydantic-core-2.14.6 | 1.4 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "openai-1.25.0        | 314 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install openai python-dotenv -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m今天我很\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 改我试试\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# prompt = \"下班了，今天我很\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# prompt = \"放学了，今天我很\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# prompt = \"AGI 实现了，今天我很\"\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo-instruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 我prompt+response的token的总数量\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 流式回复\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(chunk\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages/openai/resources/completions.py:528\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    527\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Completion \u001b[38;5;241m|\u001b[39m Stream[Completion]:\n\u001b[0;32m--> 528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_of\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mecho\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuffix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCompletion\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages/openai/_base_client.py:1005\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1004\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages/openai/_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages/openai/_base_client.py:1005\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1004\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages/openai/_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages/openai/_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1028\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# 加载我们的环境变量 .env 文件\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 客户端\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = \"今天我很\"  # 改我试试\n",
    "# prompt = \"下班了，今天我很\"\n",
    "# prompt = \"放学了，今天我很\"\n",
    "# prompt = \"AGI 实现了，今天我很\"\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=prompt,\n",
    "    # 我prompt+response的token\n",
    "    max_tokens=512,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.choices[0].text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2、略深一点的通俗原理\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<p>用不严密但通俗的语言描述大模型的工作原理：</p>\n",
    "<ol>\n",
    "<li>大模型阅读了人类曾说过的所有的话。这就是「<b>机器学习</b>」，这个过程叫「<b>训练</b>」</li>\n",
    "<li>把一串 token 后面跟着的不同 token 的概率存入「<b>神经网络</b>」。保存的数据就是「<b>参数</b>」，也叫「<b>权重</b>」</li>\n",
    "<li>当我们给它若干 token，大模型就能算出概率最高的下一个 token 是什么。这就是「<b>生成</b>」，也叫「<b>推理</b>」</li>\n",
    "<li>用生成的 token，再加上上文，就能继续生成下一个 token。以此类推，生成更多文字</li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "Token 是什么？\n",
    "\n",
    "1. 可能是一个英文单词，也可能是半个，三分之一个\n",
    "2. 可能是一个中文词，或者一个汉字，也可能是半个汉字，甚至三分之一个汉字\n",
    "3. 大模型在开训前，需要先训练一个 tokenizer 模型。它能把所有的文本，切成 token\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>思考：</b>\n",
    "<ol>\n",
    "<li>AI 做对的事，怎么用这个原理解释？</li>\n",
    "<li>AI 的幻觉，一本正经地胡说八道，怎么用这个原理解释？</li>\n",
    "</ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3、再深一点点\n",
    "\n",
    "这套生成机制的内核叫「Transformer 架构」。但其实，transformer 已经不是最先进的了。\n",
    "\n",
    "| 架构        | 设计者                                               | 特点                                     | 链接                                                                                                   |\n",
    "| ----------- | ---------------------------------------------------- | ---------------------------------------- | ------------------------------------------------------------------------------------------------------ |\n",
    "| Transformer | Google                                               | 最流行，几乎所有大模型都用它             | [OpenAI 的代码](https://github.com/openai/finetune-transformer-lm/blob/master/train.py)                |\n",
    "| RWKV        | [PENG Bo](https://www.zhihu.com/people/bopengbopeng) | 可并行训练，推理性能极佳，适合在端侧使用 | [官网](https://www.rwkv.com/)、[RWKV 5 训练代码](https://github.com/BlinkDL/RWKV-LM/tree/main/RWKV-v5) |\n",
    "| Mamba       | CMU & Princeton University                           | 性能更佳，尤其适合长文本生成             | [GitHub](https://github.com/state-spaces/mamba)                                                        |\n",
    "\n",
    "\n",
    "Transformer 的可视化 https://bbycroft.net/llm.\n",
    "\n",
    "关于 Transformer 的详细原理，请查看 https://zhuanlan.zhihu.com/p/345680792.\n",
    "\n",
    "- 神经网络的训练基础原理\n",
    "- 自然语言模型的建模\n",
    "- 注意力机制\n",
    "- 自注意力机制\n",
    "- Transformer Block\n",
    "\n",
    "后面我们会在课程的延伸部分，给大家讲解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、用好 AI 的核心心法\n",
    "\n",
    "OpenAI 首席科学家 Ilya Sutskever 说过：\n",
    "\n",
    "> 数字神经网络和人脑的生物神经网络，在数学原理上是一样的。\n",
    "\n",
    "所以，我们要：\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "把 AI 当人看。<br>\n",
    "把 AI 当人看。<br>\n",
    "把 AI 当人看。\n",
    "</div>\n",
    "\n",
    "我和中科院院士张钹交流时，他说了类似的观点：「和人怎么相处，就和 AI 怎么相处。」\n",
    "\n",
    "1. 用「当人看」来理解 AI\n",
    "2. 用「当人看」来控制 AI\n",
    "3. 用「当人看」来说服用户正确看待 AI 的不足\n",
    "\n",
    "这是贯彻整门课，甚至我们与 AI 为伴的生涯的心法。这里有三个原因：\n",
    "\n",
    "**第一，记忆与遗忘机制**\n",
    "人类记忆：人的记忆并非无限容量且永久保存，而是有选择性的存储、遗忘，并通过重复加强记忆。\n",
    "\n",
    "AI记忆：类似地，GPT等大型语言模型也存在某种程度上的“健忘”，它们虽然能记住大量的训练数据，但在长序列生成时，随着距离输入端的信息越远，其对早前内容的记忆也会逐渐减弱，类似于人类短期记忆的局限性。\n",
    "\n",
    "\n",
    "\n",
    "**第二，上下文依赖**\n",
    "人类理解：我们在交流中理解一句话的意思时，会依赖前面所说的内容，甚至包括背景知识和社会常识。你对同事说：你把昨天那个事情处理一下。如果他没有参与过事情的讨论，那肯定一脸懵逼。\n",
    "\n",
    "AI上下文理解：GPT同样依赖上下文信息，在处理自然语言任务时，只有在充分理解了前文的基础上，才能准确预测下一个词语或生成连贯的句子，这与人类理解语言的方式十分相近。\n",
    "\n",
    "\n",
    "\n",
    "**第三，渐进式学习与适应**\n",
    "人类学习：我们无法一次性吸收所有新知识，需要逐步积累、迭代学习，并结合实践经验形成深刻理解。\n",
    "\n",
    "AI学习：即使像GPT这样的强大模型，在面对全新领域或未见过的任务时，也需要经过多次迭代优化和微调，才能更好地适应新的应用场景，这一过程体现了AI与人类学习过程的相似之处。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "## 六、大模型应用架构\n",
    "\n",
    "大模型技术分两个部分：\n",
    "\n",
    "1. **训练基础大模型**：全世界只需要 1000 人做这个\n",
    "2. **建造大模型应用**：所有技术人，甚至所有人，都需要掌握\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "大模型应用技术特点：<strong>门槛低，天花板高。</strong>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1、典型业务架构\n",
    "\n",
    "<img src=\"./business_arch.webp\" style=\"margin-left: 0px\" width=700px>\n",
    "\n",
    "Agent 还太超前，Copilot 值得追求。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2、技术架构\n",
    "\n",
    "#### 纯 Prompt\n",
    "\n",
    "就像和一个人对话，你说一句，ta 回一句，你再说一句，ta 再回一句……\n",
    "\n",
    "<img src=\"./prompt_arch.png\" style=\"margin-left: 0px\" width=300px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent + Function Calling\n",
    "\n",
    "- Agent：AI 主动提要求\n",
    "- Function Calling：AI 要求执行某个函数\n",
    "- 场景举例：你问过年去哪玩，ta 先反问你有多少预算\n",
    "\n",
    "<img src=\"./func_arch.png\" style=\"margin-left: 0px\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG（Retrieval-Augmented Generation）\n",
    "\n",
    "- Embeddings：把文字转换为更易于相似度计算的编码。这种编码叫**向量**\n",
    "- 向量数据库：把向量存起来，方便查找\n",
    "- 向量搜索：根据输入向量，找到最相似的向量\n",
    "- 场景举例：考试时，看到一道题，到书上找相关内容，再结合题目组成答案。然后，就都忘了\n",
    "\n",
    "<img src=\"./embeddings_arch.png\" style=\"margin-left: 0px\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuning\n",
    "\n",
    "努力学习考试内容，长期记住，活学活用。\n",
    "\n",
    "<img src=\"./tech_arch.png\" style=\"margin-left: 0px\" width=700px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3、如何选择技术路线\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "面对一个需求，如何选择技术方案？下面是个不严谨但常用思路。\n",
    "\n",
    "<img src=\"./tech_solution.png\" style=\"margin-left: 0px\" width=700px>\n",
    "\n",
    "值得尝试 Fine-tuning 的情况：\n",
    "\n",
    "1. 提高大模型的稳定性\n",
    "2. 用户量大，降低推理成本的意义很大\n",
    "3. 提高大模型的生成速度\n",
    "4. 修正知识理解，调整部分语言风格，提高安全性\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>思考：</b>\n",
    "<ol>\n",
    "<li>一家小型做电商出口的公司，做一个企业内部的客服机器人，用来帮助企业员工查询内部文档，需要选择什么技术路线</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基础模型选型，也是个重要因素。合规和安全是首要考量因素。\n",
    "\n",
    "| 需求             | 国外大模型 | 国产大模型 | 开源大模型 |\n",
    "| ---------------- | ---------- | ---------- | ---------- |\n",
    "| 国内 2C          | 🛑         | ✅         | ✅         |\n",
    "| 国内 2G          | 🛑         | ✅         | ✅         |\n",
    "| 国内 2B          | ✅         | ✅         | ✅         |\n",
    "| 出海             | ✅         | ✅         | ✅         |\n",
    "| 数据安全特别重要 | 🛑         | 🛑         | ✅         |\n",
    "\n",
    "然后用测试数据，在可以选择的模型里，做测试，找出最优。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI 全栈课程主要以 OpenAI 为例，少量介绍国产大模型，微调会讲开源大模型。因为：\n",
    "\n",
    "1. OpenAI 使用量最大，即便国内也是如此\n",
    "2. OpenAI 最好用，最先进，没有之一\n",
    "3. 其它模型都在追赶和模仿 OpenAI。学会 OpenAI，其它模型触类旁通；反之，不一定\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "## 七、体验编程调用 OpenAI API\n",
    "\n",
    "AI 全栈课程的主打语言是 Python，因为：\n",
    "\n",
    "1. Python 和 AI 是天生的一对\n",
    "2. Python 是最容易学习的编程语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1、发一条消息\n",
    "\n",
    "体验给大模型注入新知识的代码竟如此简单。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不，周末没有课。大模型课堂的上课时间是每周一、四。如果你有任何问题，随时可以问我哦！\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 加载 .env 文件到环境变量\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 初始化 OpenAI 服务。会自动从环境变量加载 OPENAI_API_KEY 和 OPENAI_BASE_URL\n",
    "client = OpenAI()\n",
    "\n",
    "# 消息\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"你是AI助手小瓜，是大模型课堂的助教。这门课每周一、四上课。\"  # 注入 prompt\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"周末上课吗？\"  # 问问题。可以改改试试\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "# 调用 GPT-3.5\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# 输出回复\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-4.36.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio)\n",
      "  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting fastapi (from gradio)\n",
      "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gradio-client==1.0.1 (from gradio)\n",
      "  Downloading gradio_client-1.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from gradio) (0.26.0)\n",
      "Collecting huggingface-hub>=0.19.3 (from gradio)\n",
      "  Downloading huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from gradio) (3.5.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from gradio) (1.22.3)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from gradio) (23.2)\n",
      "Collecting pandas<3.0,>=1.0 (from gradio)\n",
      "  Downloading pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from gradio) (8.3.2)\n",
      "Requirement already satisfied: pydantic>=2.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from gradio) (2.5.3)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.4.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from gradio) (2.2.1)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting fsspec (from gradio-client==1.0.1->gradio)\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==1.0.1->gradio)\n",
      "  Downloading websockets-11.0.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: anyio in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (4.2.0)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: idna in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Collecting filelock (from huggingface-hub>=0.19.3->gradio)\n",
      "  Downloading filelock-3.15.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.17.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
      "Collecting numpy<3.0,>=1.0 (from gradio)\n",
      "  Downloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from pydantic>=2.0->gradio) (2.14.6)\n",
      "Requirement already satisfied: click>=8.0.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
      "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
      "  Using cached ujson-5.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi->gradio)\n",
      "  Downloading email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.6)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading httptools-0.6.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (0.21.0)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading uvloop-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading watchfiles-0.22.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/aigclass/lib/python3.9/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.4)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-4.36.1-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.0.1-py3-none-any.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading orjson-3.10.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading ruff-0.4.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached ujson-5.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "Downloading websockets-11.0.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.7/129.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.15.1-py3-none-any.whl (15 kB)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.2/345.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mmm\n",
      "\u001b[?25hDownloading watchfiles-0.22.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=d8ccdb50402574bf964c7c76baf7d126630b61b1af7947c7d0eda55d6243aa7f\n",
      "  Stored in directory: /root/.cache/pip/wheels/fd/f6/eb/b42ef38e0c6298906279494f5fcf10aee4b4bd07346b8f900b\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pydub, ffmpy, websockets, uvloop, uvicorn, ujson, tzdata, toolz, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, numpy, mdurl, importlib-resources, httptools, fsspec, filelock, dnspython, aiofiles, watchfiles, starlette, pandas, markdown-it-py, huggingface-hub, email_validator, rich, gradio-client, typer, altair, fastapi-cli, fastapi, gradio\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.3\n",
      "    Uninstalling numpy-1.22.3:\n",
      "      Successfully uninstalled numpy-1.22.3\n",
      "Successfully installed aiofiles-23.2.1 altair-5.3.0 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 filelock-3.15.1 fsspec-2024.6.0 gradio-4.36.1 gradio-client-1.0.1 httptools-0.6.1 huggingface-hub-0.23.3 importlib-resources-6.4.0 markdown-it-py-3.0.0 mdurl-0.1.2 numpy-1.26.4 orjson-3.10.4 pandas-2.2.2 pydub-0.25.1 python-multipart-0.0.9 rich-13.7.1 ruff-0.4.8 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 toolz-0.12.1 typer-0.12.3 tzdata-2024.1 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_response(message, history):\n",
    "    return random.choice([\"Yes\", \"No\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://795327ac03b0143bd2.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://795327ac03b0143bd2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.ChatInterface(random_response).launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业\n",
    "\n",
    "配置完成自己的开发环境，实现自己的第一个程序与大模型的交互。\n",
    "\n",
    "使用上面的界面，调用OpenAI来回答用户的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
