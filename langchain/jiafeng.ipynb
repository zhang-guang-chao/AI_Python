{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"1234\n"
					]
				}
			],
			"source": [
				"print(1234)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"langchain 库已安装。\n",
						"langchain_ollama 库已安装。\n"
					]
				}
			],
			"source": [
				"def check_and_install_packages(packages):\n",
				"    for package in packages:\n",
				"        try:\n",
				"            import importlib\n",
				"            importlib.import_module(package)\n",
				"            print(f\"{package} 库已安装。\")\n",
				"        except ImportError:\n",
				"            print(f\"{package} 库未安装，请使用 'pip3 install {package}' 进行安装。\")\n",
				"\n",
				"# 使用该函数检查并安装指定的包\n",
				"packages_to_check = ['langchain', 'langchain_ollama']\n",
				"check_and_install_packages(packages_to_check)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": []
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"输出： J'aime programmer.\n"
					]
				}
			],
			"source": [
				"from langchain_ollama import ChatOllama\n",
				"from langchain_core.messages import SystemMessage, HumanMessage\n",
				"\n",
				"try:\n",
				"    # 实例化 ChatOllama，使用 qwen:1.8b 模型\n",
				"    llm = ChatOllama(\n",
				"        model=\"qwen:1.8b\",\n",
				"        temperature=0,\n",
				"        # 可以根据需要添加其他参数\n",
				"    )\n",
				"\n",
				"    # 构建消息列表，使用 SystemMessage 和 HumanMessage\n",
				"    messages = [\n",
				"        SystemMessage(content=\"You are a helpful assistant that translates English to French. Translate the user sentence.\"),\n",
				"        HumanMessage(content=\"I love programming.\")\n",
				"    ]\n",
				"\n",
				"    # 调用模型进行推理\n",
				"    ai_msg = llm.invoke(messages)\n",
				"\n",
				"    # 输出结果\n",
				"    print('输出：', ai_msg.content)\n",
				"\n",
				"except Exception as e:\n",
				"    print(f\"An error occurred: {e}\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"/usr/local/bin/python3\n"
					]
				}
			],
			"source": [
				"import sys\n",
				"print(sys.executable)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 26,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"今天的上海天气预计为多云转阴，风力较小，大约在2-3级之间。白天的气温将会逐渐下降，可能会达到18℃以下，夜间温度会有所上升，可能会达到20℃以上。\n",
						"\n",
						"需要注意的是，未来几天上海的天气预报将受到多种气象条件的影响，例如台风、寒潮等，因此未来的天气变化情况可能不如预测的那么理想，敬请关注最新天气预报信息。\n"
					]
				}
			],
			"source": [
				"from langchain_ollama import OllamaLLM\n",
				"from langchain_core.prompts import ChatPromptTemplate\n",
				"from langchain_core.output_parsers import StrOutputParser\n",
				"\n",
				"# 实例化 Ollama 语言模型\n",
				"llm = OllamaLLM(model=\"qwen:1.8b\")\n",
				"\n",
				"# 定义天气预报提示模板\n",
				"prompt = ChatPromptTemplate.from_messages([\n",
				"    (\"system\", \"你是一个天气预报机器人。\"),\n",
				"    (\"user\", \"{input}\")\n",
				"])\n",
				"\n",
				"# 实例化输出解析器\n",
				"output_parser = StrOutputParser()\n",
				"\n",
				"# 构建处理链\n",
				"chain = prompt | llm | output_parser\n",
				"\n",
				"# 调用处理链并传入输入信息\n",
				"result = chain.invoke({\"input\": \"今天上海天气怎么样\"})\n",
				"\n",
				"# 输出结果\n",
				"print(result)"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.12.6"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
