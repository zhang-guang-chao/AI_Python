{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1acaf7-09a1-4b92-b05a-3e0f0122e808",
   "metadata": {},
   "source": [
    "# æœç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼ŒRetrieval-Augmented Generationï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d979fde",
   "metadata": {},
   "source": [
    "## ğŸ’¡ è¿™èŠ‚è¯¾ä¼šå¸¦ç»™ä½ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe5e70d",
   "metadata": {},
   "source": [
    "1. å¦‚ä½•ç”¨ä½ çš„å‚åŸŸæ•°æ®è¡¥å…… LLM çš„èƒ½åŠ›\n",
    "1. å¦‚ä½•æ„å»ºä½ çš„å‚åŸŸï¼ˆå‘é‡ï¼‰çŸ¥è¯†åº“\n",
    "1. æ­å»ºä¸€å¥—å®Œæ•´ RAG ç³»ç»Ÿ Pipeline\n",
    "\n",
    "å¼€å§‹ä¸Šè¯¾ï¼\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb65677",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ä¸€ã€æ¾„æ¸…ä¸€ä¸ªæ¦‚å¿µ\n",
    "\n",
    "RAG **ä¸è¦** å‚è€ƒä¸‹é¢è¿™å¼ å›¾ï¼ï¼ï¼\n",
    "\n",
    "<img src=\"rag-paper.png\" style=\"margin-left: 0px\" width=\"600px\">\n",
    "\n",
    "è¿™å¼ å›¾æºè‡ªä¸€ä¸ª[ç ”ç©¶å·¥ä½œ](https://arxiv.org/pdf/2005.11401.pdf)\n",
    "- æ­¤è®ºæ–‡ç¬¬ä¸€æ¬¡æå‡º RAG è¿™ä¸ªå«æ³•\n",
    "- åœ¨ç ”ç©¶ä¸­ï¼Œä½œè€…å°è¯•å°†æ£€ç´¢å’Œç”Ÿæˆåšåœ¨ä¸€ä¸ªæ¨¡å‹ä½“ç³»ä¸­\n",
    "\n",
    "**ä½†æ˜¯ï¼Œå®é™…ç”Ÿäº§ä¸­ï¼ŒRAG ä¸æ˜¯è¿™ä¹ˆåšçš„ï¼ï¼ï¼**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfc3852",
   "metadata": {},
   "source": [
    "## äºŒã€ä»€ä¹ˆæ˜¯æ£€ç´¢å¢å¼ºçš„ç”Ÿæˆæ¨¡å‹ï¼ˆRAGï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a059032a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.1ã€LLM å›ºæœ‰çš„å±€é™æ€§\n",
    "\n",
    "1. LLM çš„çŸ¥è¯†ä¸æ˜¯å®æ—¶çš„\n",
    "2. LLM å¯èƒ½ä¸çŸ¥é“ä½ ç§æœ‰çš„é¢†åŸŸ/ä¸šåŠ¡çŸ¥è¯†\n",
    "\n",
    "<img src=\"gpt-llama2.png\" style=\"margin-left: 0px\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab886b1",
   "metadata": {},
   "source": [
    "### 2.2ã€æ£€ç´¢å¢å¼ºç”Ÿæˆ\n",
    "\n",
    "å¤©ç„¶èƒ½æƒ³åˆ°çš„ï¼Œæˆ‘ä»¬è‡ªå·±æœ‰äº§å“çŸ¥è¯†åº“ï¼Œæœ‰æœåŠ¡æ‰‹å†Œè¿™äº›å‚ç›´é¢†åŸŸçš„ä¿¡æ¯ï¼Œèƒ½ä¸èƒ½è®©å¤§æ¨¡å‹å­¦ä¼šè¿™äº›å‚ç›´é¢†åŸŸçš„ä¿¡æ¯ã€‚\n",
    "æˆ‘ä»¬èƒ½æƒ³è±¡åˆ°çš„æ–¹æ³•æœ‰ä¸¤ç§ï¼š\n",
    "\n",
    "1. é‡æ–°è®­ç»ƒå¤§æ¨¡å‹ï¼ŒæŠŠè¿™äº›å‚ç›´é¢†åŸŸçš„æ•°æ®å–‚ç»™å¤§æ¨¡å‹ï¼Œè®©å¤§æ¨¡å‹ä»ä¸­å­¦ä¹ , è¿™æ˜¯å¾®è°ƒ\n",
    "2. ç»™å¤§æ¨¡å‹æ·»åŠ ä¸ªå¤–æŒ‚çš„çŸ¥è¯†åº“ï¼Œæˆ‘ä»¬è®©å¤§æ¨¡å‹å’Œè¿™ä¸ªçŸ¥è¯†åº“ç»“åˆç€å»ç»™ç”¨æˆ·å›ç­”é—®é¢˜\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>ç±»æ¯”ï¼š</b>\n",
    "    <li>ä½ å¯ä»¥æŠŠè¿™ä¸ªè¿‡ç¨‹æƒ³è±¡æˆå¼€å·è€ƒè¯•ã€‚è®© LLM å…ˆç¿»ä¹¦ï¼Œå†å›ç­”é—®é¢˜ã€‚è¿™ä¸ªè¿‡ç¨‹æ¨¡å‹æœ¬èº«æ˜¯ä¸å­¦ä¼šçŸ¥è¯†çš„ã€‚</li>\n",
    "    <li>å¾®è°ƒå°±æ˜¯é—­å·è€ƒè¯•ï¼Œä½ çš„å…ˆæŠŠæ‰€æœ‰çš„çŸ¥è¯†éƒ½å­¦ä¼šï¼Œæ‰èƒ½å»å›ç­”é—®é¢˜ã€‚</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e524a28",
   "metadata": {},
   "source": [
    "RAGï¼ˆRetrieval Augmented Generationï¼‰é¡¾åæ€ä¹‰ï¼Œé€šè¿‡**æ£€ç´¢**çš„æ–¹æ³•æ¥å¢å¼º**ç”Ÿæˆæ¨¡å‹**çš„èƒ½åŠ›ã€‚\n",
    "\n",
    "<video src=\"RAG.mp4\" controls=\"controls\" width=800px style=\"margin-left: 0px\"></video>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc536ba",
   "metadata": {},
   "source": [
    "## ä¸‰ã€RAG ç³»ç»Ÿçš„åŸºæœ¬æ­å»ºæµç¨‹\n",
    "\n",
    "æ­å»ºè¿‡ç¨‹ï¼š\n",
    "\n",
    "1. æ–‡æ¡£åŠ è½½ï¼Œå¹¶æŒ‰ä¸€å®šæ¡ä»¶**åˆ‡å‰²**æˆç‰‡æ®µ\n",
    "2. å°†åˆ‡å‰²çš„æ–‡æœ¬ç‰‡æ®µçŒå…¥**æ£€ç´¢å¼•æ“**\n",
    "3. å°è£…**æ£€ç´¢æ¥å£**ï¼šèƒ½ä»æ–‡æ¡£é‡Œæœç´¢å‡ºç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ\n",
    "4. æ„å»º**è°ƒç”¨æµç¨‹**ï¼šQuery -> æ£€ç´¢ -> Prompt -> LLM -> å›å¤\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ebe77",
   "metadata": {},
   "source": [
    "### 3.1ã€æ–‡æ¡£çš„åŠ è½½ä¸åˆ‡å‰²\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90e32dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.34.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from openai) (4.4.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from openai) (1.10.16)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Using cached openai-1.34.0-py3-none-any.whl (325 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, openai\n",
      "Successfully installed distro-1.9.0 openai-1.34.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b27a296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfminer.six\n",
      "  Using cached pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from pdfminer.six) (3.3.2)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six)\n",
      "  Downloading cryptography-42.0.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
      "Using cached pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "Downloading cryptography-42.0.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cryptography, pdfminer.six\n",
      "Successfully installed cryptography-42.0.8 pdfminer.six-20231228\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# å®‰è£… pdf è§£æåº“\n",
    "!pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68079010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac932a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(filename, page_numbers=None, min_line_length=1):\n",
    "    '''ä» PDF æ–‡ä»¶ä¸­ï¼ˆæŒ‰æŒ‡å®šé¡µç ï¼‰æå–æ–‡å­—'''\n",
    "    paragraphs = []\n",
    "    buffer = ''\n",
    "    full_text = ''\n",
    "    # æå–å…¨éƒ¨æ–‡æœ¬\n",
    "    for i, page_layout in enumerate(extract_pages(filename)):\n",
    "        # å¦‚æœæŒ‡å®šäº†é¡µç èŒƒå›´ï¼Œè·³è¿‡èŒƒå›´å¤–çš„é¡µ\n",
    "        if page_numbers is not None and i not in page_numbers:\n",
    "            continue\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, LTTextContainer):\n",
    "                full_text += element.get_text() + '\\n'\n",
    "                \n",
    "    # æŒ‰ç©ºè¡Œåˆ†éš”ï¼Œå°†æ–‡æœ¬é‡æ–°ç»„ç»‡æˆæ®µè½\n",
    "    lines = full_text.split('\\n')\n",
    "    for text in lines:\n",
    "        if len(text) >= min_line_length:\n",
    "            buffer += (' '+text) if not text.endswith('-') else text.strip('-')\n",
    "        elif buffer:\n",
    "            paragraphs.append(buffer)\n",
    "            buffer = ''\n",
    "    if buffer:\n",
    "        paragraphs.append(buffer)\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5724b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = extract_text_from_pdf(\"llama2.pdf\", min_line_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d156c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Llama 2: Open Foundation and Fine-Tuned Chat Models\n",
      "\n",
      " Hugo Touvronâˆ— Louis Martinâ€  Kevin Stoneâ€  Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller Cynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang Ross Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang Angela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic Sergey Edunov Thomas Scialomâˆ—\n",
      "\n",
      " GenAI, Meta\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for para in paragraphs[:3]:\n",
    "    print(para+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36b0fc0",
   "metadata": {},
   "source": [
    "## 3.2ã€æ£€ç´¢å¼•æ“\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968c043c",
   "metadata": {},
   "source": [
    "è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨å…ˆè¿›çš„å¼€æºæœç´¢å¼•æ“ ElasticSearchï¼Œå®ƒå¯ä»¥å®ç°å„ç§åœºæ™¯ä¸‹çš„æœç´¢åŠŸèƒ½ã€‚\n",
    "\n",
    "å®˜æ–¹åœ°å€ï¼šhttps://www.elastic.co/cn/elasticsearch(æœ‰å…´è¶£çš„åŒå­¦å¯ä»¥äº†è§£)\n",
    "\n",
    "### å®‰è£… ES æœåŠ¡å™¨\n",
    "\n",
    "å®‰è£…æ•™ç¨‹åœ°å€ https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html ã€‚\n",
    "ï¼ˆå¯ä»¥ä½¿ç”¨ cursor å‚è€ƒå­¦ä¹ ï¼‰\n",
    "\n",
    "å®‰è£…åï¼Œå¯ä»¥é€šè¿‡ä¸åŒç³»ç»Ÿçš„æœåŠ¡çŠ¶æ€ç›‘æµ‹æŒ‡ä»¤æŸ¥çœ‹ ES è¿è¡ŒçŠ¶æ€ï¼Œè¿™é‡Œæˆ‘çš„ centos æŒ‡ä»¤ä¸º `service elasticsearch status`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431a6356",
   "metadata": {},
   "source": [
    "### å®‰è£… ES å®¢æˆ·ç«¯ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c52191c-fd64-4816-9da3-0423ff2aaf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch7\n",
      "  Using cached elasticsearch7-7.17.9-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting urllib3<2,>=1.21.1 (from elasticsearch7)\n",
      "  Using cached urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from elasticsearch7) (2024.6.2)\n",
      "Using cached elasticsearch7-7.17.9-py2.py3-none-any.whl (386 kB)\n",
      "Using cached urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "Installing collected packages: urllib3, elasticsearch7\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.1\n",
      "    Uninstalling urllib3-2.2.1:\n",
      "      Successfully uninstalled urllib3-2.2.1\n",
      "Successfully installed elasticsearch7-7.17.9 urllib3-1.26.18\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch7  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb2ad0-7863-4506-b9d4-c58b44e08411",
   "metadata": {},
   "source": [
    "### å®‰è£…NLTKï¼ˆæ–‡æœ¬å¤„ç†æ–¹æ³•åº“ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01f80d66-54db-4fa6-b547-ac8211a63252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: click in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from nltk) (8.1.7)\n",
      "Collecting joblib (from nltk)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.5.15-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from nltk) (4.66.4)\n",
      "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading regex-2024.5.15-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m776.2/776.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: regex, joblib, nltk\n",
      "Successfully installed joblib-1.4.2 nltk-3.8.1 regex-2024.5.15\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d8609ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch7 import Elasticsearch, helpers\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")  # å±è”½ ES çš„ä¸€äº›Warnings\n",
    "\n",
    "# ä¸‹è½½åˆ†è¯å™¨å’Œåœç”¨è¯åº“\n",
    "nltk.download('punkt')  # è‹±æ–‡åˆ‡è¯ã€è¯æ ¹ã€åˆ‡å¥ç­‰æ–¹æ³•\n",
    "nltk.download('stopwords')  # è‹±æ–‡åœç”¨è¯åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54796cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_keywords(input_string):\n",
    "    '''ï¼ˆè‹±æ–‡ï¼‰æ–‡æœ¬åªä¿ç•™å…³é”®å­—'''\n",
    "    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢æ‰€æœ‰éå­—æ¯æ•°å­—çš„å­—ç¬¦ä¸ºç©ºæ ¼\n",
    "    no_symbols = re.sub(r'[^a-zA-Z0-9\\s]', ' ', input_string)\n",
    "    word_tokens = word_tokenize(no_symbols)\n",
    "    # åŠ è½½åœç”¨è¯è¡¨\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    ps = PorterStemmer()\n",
    "    # å»åœç”¨è¯ï¼Œå–è¯æ ¹\n",
    "    filtered_sentence = [ps.stem(w)\n",
    "                         for w in word_tokens if not w.lower() in stop_words]\n",
    "    return ' '.join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca912d12-4f8f-4f3d-83fa-77a34301814f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mani paramet llama 2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_keywords('how many parameters does llama 2 have?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4818da82",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "æ­¤å¤„ to_keywords ä¸ºé’ˆå¯¹è‹±æ–‡çš„å®ç°ï¼Œé’ˆå¯¹ä¸­æ–‡çš„å®ç°è¯·å‚è€ƒ chinese_utils.py\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc000a0",
   "metadata": {},
   "source": [
    "å°†æ–‡æœ¬çŒå…¥æ£€ç´¢å¼•æ“\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a83e3664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(983, [])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. åˆ›å»ºElasticsearchè¿æ¥\n",
    "es = Elasticsearch(\n",
    "    hosts=['http://localhost:9200'],  # æœåŠ¡åœ°å€ä¸ç«¯å£\n",
    "    # http_auth=(\"elastic\", \"FKaB1Jpz0Rlw0l6G\"),  # ç”¨æˆ·åï¼Œå¯†ç \n",
    ")\n",
    "\n",
    "# 2. å®šä¹‰ç´¢å¼•åç§°\n",
    "index_name = \"teacher_demo_index_tmp\"\n",
    "\n",
    "# 3. å¦‚æœç´¢å¼•å·²å­˜åœ¨ï¼Œåˆ é™¤å®ƒï¼ˆä»…ä¾›æ¼”ç¤ºï¼Œå®é™…åº”ç”¨æ—¶ä¸éœ€è¦è¿™æ­¥ï¼‰\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "\n",
    "# 4. åˆ›å»ºç´¢å¼•\n",
    "es.indices.create(index=index_name)\n",
    "\n",
    "# 5. çŒåº“æŒ‡ä»¤ï¼Œæ„å»ºç´¢å¼•\n",
    "actions = [\n",
    "    {\n",
    "        \"_index\": index_name,\n",
    "        \"_source\": {\n",
    "            \"keywords\": to_keywords(para),\n",
    "            \"text\": para\n",
    "        }\n",
    "    }\n",
    "    for para in paragraphs\n",
    "]\n",
    "\n",
    "# 6. æ–‡æœ¬çŒåº“\n",
    "helpers.bulk(es, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f7376a",
   "metadata": {},
   "source": [
    "å®ç°å…³é”®å­—æ£€ç´¢\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c7ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query_string, top_n=3):\n",
    "    # ES çš„æŸ¥è¯¢è¯­è¨€\n",
    "    search_query = {\n",
    "        \"match\": {\n",
    "            \"keywords\": to_keywords(query_string)\n",
    "        }\n",
    "    }\n",
    "    res = es.search(index=index_name, query=search_query, size=top_n)\n",
    "    return [hit[\"_source\"][\"text\"] for hit in res[\"hits\"][\"hits\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57a29286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Llama 2 comes in a range of parameter sizesâ€”7B, 13B, and 70Bâ€”as well as pretrained and fine-tuned variations.\n",
      "\n",
      " 1. Llama 2, an updated version of Llama 1, trained on a new mix of publicly available data. We also increased the size of the pretraining corpus by 40%, doubled the context length of the model, and adopted grouped-query attention (Ainslie et al., 2023). We are releasing variants of Llama 2 with 7B, 13B, and 70B parameters. We have also trained 34B variants, which we report on in this paper but are not releasing.Â§\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = search(\"how many parameters does llama 2 have?\", 2)\n",
    "for r in results:\n",
    "    print(r+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b15f8",
   "metadata": {},
   "source": [
    "### 3.3ã€LLM æ¥å£å°è£…\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b132e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())  # è¯»å–æœ¬åœ° .env æ–‡ä»¶ï¼Œé‡Œé¢å®šä¹‰äº† OPENAI_API_KEY\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4148f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    '''å°è£… openai æ¥å£'''\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,  # æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§ï¼Œ0 è¡¨ç¤ºéšæœºæ€§æœ€å°\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc24292b",
   "metadata": {},
   "source": [
    "### 3.4ã€Prompt æ¨¡æ¿\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3116b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(prompt_template, **kwargs):\n",
    "    '''å°† Prompt æ¨¡æ¿èµ‹å€¼'''\n",
    "    prompt = prompt_template\n",
    "    for k, v in kwargs.items():\n",
    "        if isinstance(v, str):\n",
    "            val = v\n",
    "        elif isinstance(v, list) and all(isinstance(elem, str) for elem in v):\n",
    "            val = '\\n'.join(v)\n",
    "        else:\n",
    "            val = str(v)\n",
    "        prompt = prompt.replace(f\"__{k.upper()}__\", val)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "975cac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªé—®ç­”æœºå™¨äººã€‚\n",
    "ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä¸‹è¿°ç»™å®šçš„å·²çŸ¥ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n",
    "ç¡®ä¿ä½ çš„å›å¤å®Œå…¨ä¾æ®ä¸‹è¿°å·²çŸ¥ä¿¡æ¯ã€‚ä¸è¦ç¼–é€ ç­”æ¡ˆã€‚\n",
    "å¦‚æœä¸‹è¿°å·²çŸ¥ä¿¡æ¯ä¸è¶³ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œè¯·ç›´æ¥å›å¤\"æˆ‘æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜\"ã€‚\n",
    "\n",
    "å·²çŸ¥ä¿¡æ¯:\n",
    "__INFO__\n",
    "\n",
    "ç”¨æˆ·é—®ï¼š\n",
    "__QUERY__\n",
    "\n",
    "è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef701dfa-8800-4c37-9d66-318fa121bcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ä½ æ˜¯ä¸€ä¸ªé—®ç­”æœºå™¨äººã€‚\n",
      "ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä¸‹è¿°ç»™å®šçš„å·²çŸ¥ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n",
      "ç¡®ä¿ä½ çš„å›å¤å®Œå…¨ä¾æ®ä¸‹è¿°å·²çŸ¥ä¿¡æ¯ã€‚ä¸è¦ç¼–é€ ç­”æ¡ˆã€‚\n",
      "å¦‚æœä¸‹è¿°å·²çŸ¥ä¿¡æ¯ä¸è¶³ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œè¯·ç›´æ¥å›å¤\"æˆ‘æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜\"ã€‚\n",
      "\n",
      "å·²çŸ¥ä¿¡æ¯:\n",
      "a\n",
      "\n",
      "ç”¨æˆ·é—®ï¼š\n",
      "b\n",
      "\n",
      "c\n",
      "\n",
      "è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = build_prompt(prompt_template, info=\"a\", query=\"b\", key=\"c\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2febf6d2",
   "metadata": {},
   "source": [
    "### 3.5ã€RAG Pipeline åˆæ¢\n",
    "\n",
    "\n",
    "<video src=\"RAG.mp4\" controls=\"controls\" width=800px style=\"margin-left: 0px\"></video>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0723e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Prompt===\n",
      "\n",
      "ä½ æ˜¯ä¸€ä¸ªé—®ç­”æœºå™¨äººã€‚\n",
      "ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä¸‹è¿°ç»™å®šçš„å·²çŸ¥ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n",
      "ç¡®ä¿ä½ çš„å›å¤å®Œå…¨ä¾æ®ä¸‹è¿°å·²çŸ¥ä¿¡æ¯ã€‚ä¸è¦ç¼–é€ ç­”æ¡ˆã€‚\n",
      "å¦‚æœä¸‹è¿°å·²çŸ¥ä¿¡æ¯ä¸è¶³ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œè¯·ç›´æ¥å›å¤\"æˆ‘æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜\"ã€‚\n",
      "\n",
      "å·²çŸ¥ä¿¡æ¯:\n",
      " Llama 2 comes in a range of parameter sizesâ€”7B, 13B, and 70Bâ€”as well as pretrained and fine-tuned variations.\n",
      " 1. Llama 2, an updated version of Llama 1, trained on a new mix of publicly available data. We also increased the size of the pretraining corpus by 40%, doubled the context length of the model, and adopted grouped-query attention (Ainslie et al., 2023). We are releasing variants of Llama 2 with 7B, 13B, and 70B parameters. We have also trained 34B variants, which we report on in this paper but are not releasing.Â§\n",
      "\n",
      "ç”¨æˆ·é—®ï¼š\n",
      "how many parameters does llama 2 have?\n",
      "\n",
      "è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n",
      "\n",
      "===å›å¤===\n",
      "Llama 2æœ‰7Bã€13Bå’Œ70Bä¸‰ç§å‚æ•°å¤§å°ã€‚\n"
     ]
    }
   ],
   "source": [
    "user_query = \"how many parameters does llama 2 have?\"\n",
    "\n",
    "# 1. æ£€ç´¢\n",
    "search_results = search(user_query, 2)\n",
    "\n",
    "# 2. æ„å»º Prompt\n",
    "prompt = build_prompt(prompt_template, info=search_results, query=user_query)\n",
    "print(\"===Prompt===\")\n",
    "print(prompt)\n",
    "\n",
    "# 3. è°ƒç”¨ LLM\n",
    "response = get_completion(prompt)\n",
    "\n",
    "print(\"===å›å¤===\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe8d12",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>æ‰©å±•é˜…è¯»ï¼š</b>\n",
    "<ol>\n",
    "<ul>Elasticsearchï¼ˆç®€ç§°ESï¼‰æ˜¯ä¸€ä¸ªå¹¿æ³›åº”ç”¨çš„å¼€æºæœç´¢å¼•æ“: https://www.elastic.co/</ul>\n",
    "<ul>å…³äºESçš„å®‰è£…ã€éƒ¨ç½²ç­‰çŸ¥è¯†ï¼Œç½‘ä¸Šå¯ä»¥æ‰¾åˆ°å¤§é‡èµ„æ–™ï¼Œä¾‹å¦‚: https://juejin.cn/post/7104875268166123528</ul>\n",
    "<ul>å…³äºç»å…¸ä¿¡æ¯æ£€ç´¢æŠ€æœ¯çš„æ›´å¤šç»†èŠ‚ï¼Œå¯ä»¥å‚è€ƒ: https://nlp.stanford.edu/IR-book/information-retrieval-book.html</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156d3dd7",
   "metadata": {},
   "source": [
    "### 3.6ã€å…³é”®å­—æ£€ç´¢çš„å±€é™æ€§\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71203461",
   "metadata": {},
   "source": [
    "åŒä¸€ä¸ªè¯­ä¹‰ï¼Œç”¨è¯ä¸åŒï¼Œå¯èƒ½å¯¼è‡´æ£€ç´¢ä¸åˆ°æœ‰æ•ˆçš„ç»“æœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc07e425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2. Llama 2-Chat, a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release\n",
      "\n",
      " Figure 20: Distribution shift for progressive versions of Llama 2-Chat, from SFT models towards RLHF.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_query=\"Does llama 2 have a chat version?\"\n",
    "# user_query = \"Does llama 2 have a conversational variant?\"\n",
    "\n",
    "search_results = search(user_query, 2)\n",
    "\n",
    "for res in search_results:\n",
    "    print(res+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcdd909",
   "metadata": {},
   "source": [
    "## å››ã€å‘é‡æ£€ç´¢\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca1b0e",
   "metadata": {},
   "source": [
    "### 4.1ã€æ–‡æœ¬å‘é‡ï¼ˆText Embeddingsï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e571b807",
   "metadata": {},
   "source": [
    "1. å°†æ–‡æœ¬è½¬æˆä¸€ç»„æµ®ç‚¹æ•°ï¼šæ¯ä¸ªä¸‹æ ‡ $i$ï¼Œå¯¹åº”ä¸€ä¸ªç»´åº¦\n",
    "2. æ•´ä¸ªæ•°ç»„å¯¹åº”ä¸€ä¸ª $n$ ç»´ç©ºé—´çš„ä¸€ä¸ªç‚¹ï¼Œå³**æ–‡æœ¬å‘é‡**åˆå« Embeddings\n",
    "3. å‘é‡ä¹‹é—´å¯ä»¥è®¡ç®—è·ç¦»ï¼Œè·ç¦»è¿œè¿‘å¯¹åº”**è¯­ä¹‰ç›¸ä¼¼åº¦**å¤§å°\n",
    "\n",
    "<br />\n",
    "<img src=\"embeddings.png\" style=\"margin-left: 0px\" width=800px>\n",
    "<br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11835a3",
   "metadata": {},
   "source": [
    "### 4.1.1ã€æ–‡æœ¬å‘é‡æ˜¯æ€ä¹ˆå¾—åˆ°çš„ï¼ˆé€‰ï¼‰\n",
    "\n",
    "1. æ„å»ºç›¸å…³ï¼ˆæ­£ç«‹ï¼‰ä¸ä¸ç›¸å…³ï¼ˆè´Ÿä¾‹ï¼‰çš„å¥å­å¯¹å„¿æ ·æœ¬\n",
    "2. è®­ç»ƒåŒå¡”å¼æ¨¡å‹ï¼Œè®©æ­£ä¾‹é—´çš„è·ç¦»å°ï¼Œè´Ÿä¾‹é—´çš„è·ç¦»å¤§\n",
    "\n",
    "ä¾‹å¦‚ï¼š\n",
    "\n",
    "<img src=\"sbert.png\" style=\"margin-left: 0px\" width=500px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e79d9e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>æ‰©å±•é˜…è¯»ï¼šhttps://www.sbert.net</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a937becf",
   "metadata": {},
   "source": [
    "### 4.2ã€å‘é‡é—´çš„ç›¸ä¼¼åº¦è®¡ç®—\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2622e44",
   "metadata": {},
   "source": [
    "<img src=\"sim.png\" style=\"margin-left: 0px\" width=500px>\n",
    "\n",
    "ä½™å¼¦ç›¸ä¼¼åº¦å–å€¼ä¸º-1åˆ°1ï¼Œ-1æœ€ä¸ç›¸ä¼¼ï¼Œ1æœ€ç›¸ä¼¼ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6965d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82461a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    '''ä½™å¼¦è·ç¦» -- è¶Šå¤§è¶Šç›¸ä¼¼'''\n",
    "    return dot(a, b)/(norm(a)*norm(b))\n",
    "\n",
    "\n",
    "def l2(a, b):\n",
    "    '''æ¬§å¼è·ç¦» -- è¶Šå°è¶Šç›¸ä¼¼'''\n",
    "    x = np.asarray(a)-np.asarray(b)\n",
    "    return norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cebc818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts, model=\"text-embedding-ada-002\",dimensions=None):\n",
    "    '''å°è£… OpenAI çš„ Embedding æ¨¡å‹æ¥å£ï¼Œæ–‡æ¡£åœ°å€ https://platform.openai.com/docs/guides/embeddings/what-are-embeddings'''\n",
    "    if model == \"text-embedding-ada-002\":\n",
    "        dimensions = None\n",
    "    if dimensions:\n",
    "        data = client.embeddings.create(input=texts, model=model, dimensions=dimensions).data\n",
    "    else:\n",
    "        data = client.embeddings.create(input=texts, model=model).data\n",
    "    return [x.embedding for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bccfe472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.007280634716153145, -0.006147929932922125, -0.010664181783795357, 0.001484171487390995, -0.010678750462830067, 0.029253656044602394, -0.01976952701807022, 0.005444996990263462, -0.01687038503587246, -0.01207733154296875]\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "test_query = [\"æµ‹è¯•æ–‡æœ¬\"]\n",
    "vec = get_embeddings(test_query, dimensions=128)[0]\n",
    "print(vec[:10])\n",
    "print(len(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76e2f784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine distance:\n",
      "1.0\n",
      "0.7622749944010911\n",
      "0.7563038106493583\n",
      "0.7426665802579038\n",
      "0.7079273699608006\n",
      "0.7254355321045071\n",
      "\n",
      "Euclidean distance:\n",
      "0.0\n",
      "0.6895288502682276\n",
      "0.6981349637998768\n",
      "0.7174028746492277\n",
      "0.764293983363683\n",
      "0.7410323668625171\n"
     ]
    }
   ],
   "source": [
    "# query = \"å›½é™…äº‰ç«¯\"\n",
    "\n",
    "# ä¸”èƒ½æ”¯æŒè·¨è¯­è¨€\n",
    "query = \"global conflicts\"\n",
    "\n",
    "documents = [\n",
    "    \"è”åˆå›½å°±è‹ä¸¹è¾¾å°”å¯Œå°”åœ°åŒºå¤§è§„æ¨¡æš´åŠ›äº‹ä»¶å‘å‡ºè­¦å‘Š\",\n",
    "    \"åœŸè€³å…¶ã€èŠ¬å…°ã€ç‘å…¸ä¸åŒ—çº¦ä»£è¡¨å°†ç»§ç»­å°±ç‘å…¸â€œå…¥çº¦â€é—®é¢˜è¿›è¡Œè°ˆåˆ¤\",\n",
    "    \"æ—¥æœ¬å²é˜œå¸‚é™†ä¸Šè‡ªå«é˜Ÿå°„å‡»åœºå†…å‘ç”Ÿæªå‡»äº‹ä»¶ 3äººå—ä¼¤\",\n",
    "    \"å›½å®¶æ¸¸æ³³ä¸­å¿ƒï¼ˆæ°´ç«‹æ–¹ï¼‰ï¼šæ¢å¤æ¸¸æ³³ã€å¬‰æ°´ä¹å›­ç­‰æ°´ä¸Šé¡¹ç›®è¿è¥\",\n",
    "    \"æˆ‘å›½é¦–æ¬¡åœ¨ç©ºé—´ç«™å¼€å±•èˆ±å¤–è¾å°„ç”Ÿç‰©å­¦æš´éœ²å®éªŒ\",\n",
    "]\n",
    "\n",
    "query_vec = get_embeddings([query])[0]\n",
    "doc_vecs = get_embeddings(documents)\n",
    "\n",
    "print(\"Cosine distance:\")\n",
    "print(cos_sim(query_vec, query_vec))\n",
    "\n",
    "for vec in doc_vecs:\n",
    "    print(cos_sim(query_vec, vec))\n",
    "\n",
    "print(\"\\nEuclidean distance:\")\n",
    "print(l2(query_vec, query_vec))\n",
    "for vec in doc_vecs:\n",
    "    print(l2(query_vec, vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c868fa09-e858-43e7-a9c2-b727109977b1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>æ€è€ƒï¼š</b>å¦‚æœæˆ‘æœ‰1000ä¸‡ä¸ªæ–‡æ¡£è¦å»åšç›¸ä¼¼åº¦çš„è®¡ç®—ï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿ\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f32378",
   "metadata": {},
   "source": [
    "### 4.3ã€å‘é‡æ•°æ®åº“\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf41f4d",
   "metadata": {},
   "source": [
    "ä¸€ä¸ªä¸ªçš„æ¯”è¾ƒæ•ˆç‡å®åœ¨è¿‡ä½ï¼Œæˆ‘ä»¬éœ€è¦ä¸“ä¸šçš„æ•°æ®åº“æ¥å¸®åŠ©æˆ‘ä»¬å®Œæˆè¿™ç§å¯¹äºå‘é‡çš„è®¡ç®—çš„æ“ä½œã€‚\n",
    "\n",
    "**å‘é‡æ•°æ®åº“**ï¼Œæ˜¯ä¸“é—¨ä¸ºå‘é‡æ£€ç´¢è®¾è®¡çš„ä¸­é—´ä»¶ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ç§å¼€æºçš„å‘é‡æ•°æ®åº“ chromadbï¼Œæ–‡æ¡£åœ°å€ https://docs.trychroma.com/getting-started#1.-install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b562366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb==0.3.29 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (0.3.29)\n",
      "Requirement already satisfied: pandas>=1.3 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.28 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (2.32.3)\n",
      "Requirement already satisfied: pydantic<2.0,>=1.9 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (1.10.16)\n",
      "Requirement already satisfied: hnswlib>=0.7 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (0.8.0)\n",
      "Requirement already satisfied: clickhouse-connect>=0.5.7 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (0.7.12)\n",
      "Requirement already satisfied: duckdb>=0.7.1 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (1.0.0)\n",
      "Requirement already satisfied: fastapi==0.85.1 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (0.85.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (1.24.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (4.12.2)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (3.5.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (1.16.3)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (4.66.4)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (7.7.0)\n",
      "Requirement already satisfied: graphlib-backport>=1.0.3 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from chromadb==0.3.29) (1.1.0)\n",
      "Requirement already satisfied: starlette==0.20.4 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from fastapi==0.85.1->chromadb==0.3.29) (0.20.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from starlette==0.20.4->fastapi==0.85.1->chromadb==0.3.29) (4.4.0)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.29) (2024.6.2)\n",
      "Requirement already satisfied: urllib3>=1.26 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.29) (1.26.18)\n",
      "Requirement already satisfied: pytz in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.29) (2024.1)\n",
      "Requirement already satisfied: zstandard in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.29) (0.22.0)\n",
      "Requirement already satisfied: lz4 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.29) (4.3.3)\n",
      "Requirement already satisfied: coloredlogs in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb==0.3.29) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb==0.3.29) (24.3.25)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb==0.3.29) (24.1)\n",
      "Requirement already satisfied: protobuf in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb==0.3.29) (4.25.3)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb==0.3.29) (1.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from pandas>=1.3->chromadb==0.3.29) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from pandas>=1.3->chromadb==0.3.29) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from posthog>=2.4.0->chromadb==0.3.29) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from posthog>=2.4.0->chromadb==0.3.29) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from posthog>=2.4.0->chromadb==0.3.29) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from requests>=2.28->chromadb==0.3.29) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from requests>=2.28->chromadb==0.3.29) (3.7)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from tokenizers>=0.13.2->chromadb==0.3.29) (0.23.4)\n",
      "Requirement already satisfied: click>=7.0 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.3.29) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.3.29) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (1.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (6.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.29) (12.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.3.29) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.3.29) (2024.6.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.3.29) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.3.29) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi==0.85.1->chromadb==0.3.29) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/aigclass3.8/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi==0.85.1->chromadb==0.3.29) (1.2.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install chromadb==0.3.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae3681ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸ºäº†æ¼”ç¤ºæ–¹ä¾¿ï¼Œæˆ‘ä»¬åªå–ä¸¤é¡µï¼ˆç¬¬ä¸€ç« ï¼‰\n",
    "paragraphs = extract_text_from_pdf(\n",
    "    \"llama2.pdf\", \n",
    "    page_numbers=[2, 3], \n",
    "    min_line_length=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe3071c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "\n",
    "class MyVectorDBConnector:\n",
    "    def __init__(self, collection_name, embedding_fn):\n",
    "        chroma_client = chromadb.Client(Settings(allow_reset=True))\n",
    "\n",
    "        # ä¸ºäº†æ¼”ç¤ºï¼Œå®é™…ä¸éœ€è¦æ¯æ¬¡ reset()\n",
    "        chroma_client.reset()\n",
    "\n",
    "        # åˆ›å»ºä¸€ä¸ª collection\n",
    "        self.collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "        self.embedding_fn = embedding_fn\n",
    "\n",
    "    def add_documents(self, documents):\n",
    "        '''å‘ collection ä¸­æ·»åŠ æ–‡æ¡£ä¸å‘é‡'''\n",
    "        self.collection.add(\n",
    "            embeddings=self.embedding_fn(documents),  # æ¯ä¸ªæ–‡æ¡£çš„å‘é‡\n",
    "            documents=documents,  # æ–‡æ¡£çš„åŸæ–‡\n",
    "            ids=[f\"id{i}\" for i in range(len(documents))]  # æ¯ä¸ªæ–‡æ¡£çš„ id\n",
    "        )\n",
    "\n",
    "    def search(self, query, top_n):\n",
    "        '''æ£€ç´¢å‘é‡æ•°æ®åº“'''\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=self.embedding_fn([query]),\n",
    "            n_results=top_n\n",
    "        )\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0984edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºä¸€ä¸ªå‘é‡æ•°æ®åº“å¯¹è±¡\n",
    "vector_db = MyVectorDBConnector(\"demo\", get_embeddings)\n",
    "# å‘å‘é‡æ•°æ®åº“ä¸­æ·»åŠ æ–‡æ¡£\n",
    "vector_db.add_documents(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d521942",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Llama 2æœ‰å¤šå°‘å‚æ•°\"\n",
    "results = vector_db.search(user_query, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb60bb48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. Llama 2, an updated version of Llama 1, trained on a new mix of publicly available data. We also increased the size of the pretraining corpus by 40%, doubled the context length of the model, and adopted grouped-query attention (Ainslie et al., 2023). We are releasing variants of Llama 2 with 7B, 13B, and 70B parameters. We have also trained 34B variants, which we report on in this paper but are not releasing.Â§\n",
      "\n",
      " In this work, we develop and release Llama 2, a family of pretrained and fine-tuned LLMs, Llama 2 and Llama 2-Chat, at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested, Llama 2-Chat models generally perform better than existing open-source models. They also appear to be on par with some of the closed-source models, at least on the human evaluations we performed (see Figures 1 and 3). We have taken measures to increase the safety of these models, using safety-specific data annotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally, this paper contributes a thorough description of our fine-tuning methodology and approach to improving LLM safety. We hope that this openness will enable the community to reproduce fine-tuned LLMs and continue to improve the safety of those models, paving the way for more responsible development of LLMs. We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for para in results['documents'][0]:\n",
    "    print(para+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6a64af",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>æ¾„æ¸…å‡ ä¸ªå…³é”®æ¦‚å¿µï¼š</b><ul>\n",
    "    <li>å‘é‡æ•°æ®åº“çš„æ„ä¹‰æ˜¯å¿«é€Ÿçš„æ£€ç´¢ï¼›</li>\n",
    "    <li>å‘é‡æ•°æ®åº“æœ¬èº«ä¸ç”Ÿæˆå‘é‡ï¼Œå‘é‡æ˜¯ç”± Embedding æ¨¡å‹äº§ç”Ÿçš„ï¼›</li>\n",
    "    <li>å‘é‡æ•°æ®åº“ä¸ä¼ ç»Ÿçš„å…³ç³»å‹æ•°æ®åº“æ˜¯äº’è¡¥çš„ï¼Œä¸æ˜¯æ›¿ä»£å…³ç³»ï¼Œåœ¨å®é™…åº”ç”¨ä¸­æ ¹æ®å®é™…éœ€æ±‚ç»å¸¸åŒæ—¶ä½¿ç”¨ã€‚</li>\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1447f7d9",
   "metadata": {},
   "source": [
    "### 4.3.1ã€å‘é‡æ•°æ®åº“æœåŠ¡\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72302d6e",
   "metadata": {},
   "source": [
    "Server ç«¯\n",
    "\n",
    "```sh\n",
    "chroma run --path /db_path\n",
    "```\n",
    "\n",
    "Client ç«¯\n",
    "\n",
    "```python\n",
    "import chromadb\n",
    "chroma_client = chromadb.HttpClient(host='localhost', port=8000)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdf86fd",
   "metadata": {},
   "source": [
    "### 4.3.2ã€ä¸»æµå‘é‡æ•°æ®åº“åŠŸèƒ½å¯¹æ¯”\n",
    "\n",
    "<img src=\"vectordb.png\" style=\"margin-left: 0px\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc0e5ee",
   "metadata": {},
   "source": [
    "- FAISS: Meta å¼€æºçš„å‘é‡æ£€ç´¢å¼•æ“ https://github.com/facebookresearch/faiss\n",
    "- Pinecone: å•†ç”¨å‘é‡æ•°æ®åº“ï¼Œåªæœ‰äº‘æœåŠ¡ https://www.pinecone.io/\n",
    "- Milvus: å¼€æºå‘é‡æ•°æ®åº“ï¼ŒåŒæ—¶æœ‰äº‘æœåŠ¡ https://milvus.io/\n",
    "- Weaviate: å¼€æºå‘é‡æ•°æ®åº“ï¼ŒåŒæ—¶æœ‰äº‘æœåŠ¡ https://weaviate.io/\n",
    "- Qdrant: å¼€æºå‘é‡æ•°æ®åº“ï¼ŒåŒæ—¶æœ‰äº‘æœåŠ¡ https://qdrant.tech/\n",
    "- PGVector: Postgres çš„å¼€æºå‘é‡æ£€ç´¢å¼•æ“ https://github.com/pgvector/pgvector\n",
    "- RediSearch: Redis çš„å¼€æºå‘é‡æ£€ç´¢å¼•æ“ https://github.com/RediSearch/RediSearch\n",
    "- ElasticSearch ä¹Ÿæ”¯æŒå‘é‡æ£€ç´¢ https://www.elastic.co/enterprise-search/vector-search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c049d7",
   "metadata": {},
   "source": [
    "### 4.4ã€åŸºäºå‘é‡æ£€ç´¢çš„ RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b7028d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG_Bot:\n",
    "    def __init__(self, vector_db, llm_api, n_results=2):\n",
    "        self.vector_db = vector_db\n",
    "        self.llm_api = llm_api\n",
    "        self.n_results = n_results\n",
    "\n",
    "    def chat(self, user_query):\n",
    "        # 1. æ£€ç´¢\n",
    "        search_results = self.vector_db.search(user_query, self.n_results)\n",
    "\n",
    "        # 2. æ„å»º Prompt\n",
    "        prompt = build_prompt(\n",
    "            prompt_template, info=search_results['documents'][0], query=user_query)\n",
    "\n",
    "        # 3. è°ƒç”¨ LLM\n",
    "        response = self.llm_api(prompt)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b17078a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²çŸ¥ä¿¡æ¯ä¸­æåˆ°äº†\"Llama 2-Chat\"ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºå¯¹è¯ä½¿ç”¨æƒ…å†µä¼˜åŒ–çš„Llama 2çš„ç²¾è°ƒç‰ˆæœ¬ã€‚å› æ­¤ï¼Œæ˜¯çš„ï¼ŒLlama 2æœ‰å¯¹è¯ç‰ˆã€‚\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºä¸€ä¸ªRAGæœºå™¨äºº\n",
    "bot = RAG_Bot(\n",
    "    vector_db,\n",
    "    llm_api=get_completion\n",
    ")\n",
    "\n",
    "user_query = \"llama 2æœ‰å¯¹è¯ç‰ˆå—ï¼Ÿ\"\n",
    "\n",
    "response = bot.chat(user_query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a3cf0a",
   "metadata": {},
   "source": [
    "### 4.5ã€å¦‚æœæƒ³è¦æ¢ä¸ªå›½äº§æ¨¡å‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1771afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# é€šè¿‡é‰´æƒæ¥å£è·å– access token\n",
    "def get_access_token():\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ AKï¼ŒSK ç”Ÿæˆé‰´æƒç­¾åï¼ˆAccess Tokenï¼‰\n",
    "    :return: access_tokenï¼Œæˆ–æ˜¯None(å¦‚æœé”™è¯¯)\n",
    "    \"\"\"\n",
    "    url = \"https://aip.baidubce.com/oauth/2.0/token\"\n",
    "    params = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": os.getenv('ERNIE_CLIENT_ID'),\n",
    "        \"client_secret\": os.getenv('ERNIE_CLIENT_SECRET')\n",
    "    }\n",
    "\n",
    "    return str(requests.post(url, params=params).json().get(\"access_token\"))\n",
    "\n",
    "# è°ƒç”¨æ–‡å¿ƒåƒå¸† è°ƒç”¨ BGE Embedding æ¥å£\n",
    "def get_embeddings_bge(prompts):\n",
    "    url = \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/embeddings/bge_large_en?access_token=\" + get_access_token()\n",
    "    payload = json.dumps({\n",
    "        \"input\": prompts\n",
    "    })\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    response = requests.request(\n",
    "        \"POST\", url, headers=headers, data=payload).json()\n",
    "    data = response[\"data\"]\n",
    "    return [x[\"embedding\"] for x in data]\n",
    "\n",
    "\n",
    "# è°ƒç”¨æ–‡å¿ƒ4.0å¯¹è¯æ¥å£\n",
    "def get_completion_ernie(prompt):\n",
    "\n",
    "    url = \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions_pro?access_token=\" + get_access_token()\n",
    "    payload = json.dumps({\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    response = requests.request(\n",
    "        \"POST\", url, headers=headers, data=payload).json()\n",
    "\n",
    "    return response[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e014ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºä¸€ä¸ªå‘é‡æ•°æ®åº“å¯¹è±¡\n",
    "new_vector_db = MyVectorDBConnector(\n",
    "    \"demo_ernie\",\n",
    "    embedding_fn=get_embeddings_bge\n",
    ")\n",
    "# å‘å‘é‡æ•°æ®åº“ä¸­æ·»åŠ æ–‡æ¡£\n",
    "new_vector_db.add_documents(paragraphs)\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªRAGæœºå™¨äºº\n",
    "new_bot = RAG_Bot(\n",
    "    new_vector_db,\n",
    "    llm_api=get_completion_ernie\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e393a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"how many parameters does llama 2 have?\"\n",
    "\n",
    "response = new_bot.chat(user_query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a990f018",
   "metadata": {},
   "source": [
    "### 4.6ã€OpenAI æ–°å‘å¸ƒçš„ä¸¤ä¸ª Embedding æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15605413",
   "metadata": {},
   "source": [
    "2024å¹´1æœˆ25æ—¥ï¼ŒOpenAI æ–°å‘å¸ƒäº†ä¸¤ä¸ª Embedding æ¨¡å‹\n",
    "\n",
    "- text-embedding-3-large\n",
    "- text-embedding-3-small\n",
    "\n",
    "å…¶æœ€å¤§ç‰¹ç‚¹æ˜¯ï¼Œæ”¯æŒè‡ªå®šä¹‰çš„ç¼©çŸ­å‘é‡ç»´åº¦ï¼Œä»è€Œåœ¨å‡ ä¹ä¸å½±å“æœ€ç»ˆæ•ˆæœçš„æƒ…å†µä¸‹é™ä½å‘é‡æ£€ç´¢ä¸ç›¸ä¼¼åº¦è®¡ç®—çš„å¤æ‚åº¦ã€‚\n",
    "\n",
    "é€šä¿—çš„è¯´ï¼š**è¶Šå¤§è¶Šå‡†ã€è¶Šå°è¶Šå¿«ã€‚** å®˜æ–¹å…¬å¸ƒçš„è¯„æµ‹ç»“æœ:\n",
    "\n",
    "<img src=\"mteb.png\" style=\"margin-left: 0px\" width=600px>\n",
    "\n",
    "æ³¨ï¼š[MTEB](https://huggingface.co/blog/mteb) æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡å¤šä»»åŠ¡çš„ Embedding æ¨¡å‹å…¬å¼€è¯„æµ‹é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97da8b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim: 128\n",
      "Cosine distance:\n",
      "0.2865773001182426\n",
      "0.41830986590456204\n",
      "0.21462566338499087\n",
      "0.15146227929798226\n",
      "0.17059296471763005\n",
      "\n",
      "Euclidean distance:\n",
      "1.1945063968652392\n",
      "1.0786010898034128\n",
      "1.2532951931301017\n",
      "1.3027185279508469\n",
      "1.287949624282259\n"
     ]
    }
   ],
   "source": [
    "model = \"text-embedding-3-large\"\n",
    "dimensions = 128\n",
    "\n",
    "query = \"å›½é™…äº‰ç«¯\"\n",
    "\n",
    "# ä¸”èƒ½æ”¯æŒè·¨è¯­è¨€\n",
    "# query = \"global conflicts\"\n",
    "\n",
    "documents = [\n",
    "    \"è”åˆå›½å°±è‹ä¸¹è¾¾å°”å¯Œå°”åœ°åŒºå¤§è§„æ¨¡æš´åŠ›äº‹ä»¶å‘å‡ºè­¦å‘Š\",\n",
    "    \"åœŸè€³å…¶ã€èŠ¬å…°ã€ç‘å…¸ä¸åŒ—çº¦ä»£è¡¨å°†ç»§ç»­å°±ç‘å…¸â€œå…¥çº¦â€é—®é¢˜è¿›è¡Œè°ˆåˆ¤\",\n",
    "    \"æ—¥æœ¬å²é˜œå¸‚é™†ä¸Šè‡ªå«é˜Ÿå°„å‡»åœºå†…å‘ç”Ÿæªå‡»äº‹ä»¶ 3äººå—ä¼¤\",\n",
    "    \"å›½å®¶æ¸¸æ³³ä¸­å¿ƒï¼ˆæ°´ç«‹æ–¹ï¼‰ï¼šæ¢å¤æ¸¸æ³³ã€å¬‰æ°´ä¹å›­ç­‰æ°´ä¸Šé¡¹ç›®è¿è¥\",\n",
    "    \"æˆ‘å›½é¦–æ¬¡åœ¨ç©ºé—´ç«™å¼€å±•èˆ±å¤–è¾å°„ç”Ÿç‰©å­¦æš´éœ²å®éªŒ\",\n",
    "]\n",
    "\n",
    "query_vec = get_embeddings([query],model=model,dimensions=dimensions)[0]\n",
    "doc_vecs = get_embeddings(documents,model=model,dimensions=dimensions)\n",
    "\n",
    "print(\"Dim: {}\".format(len(query_vec)))\n",
    "\n",
    "print(\"Cosine distance:\")\n",
    "for vec in doc_vecs:\n",
    "    print(cos_sim(query_vec, vec))\n",
    "\n",
    "print(\"\\nEuclidean distance:\")\n",
    "for vec in doc_vecs:\n",
    "    print(l2(query_vec, vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90485a68",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>æ‰©å±•é˜…è¯»ï¼šè¿™ç§å¯å˜é•¿åº¦çš„ Embedding æŠ€æœ¯èƒŒåçš„åŸç†å«åš <a href=\"https://arxiv.org/abs/2205.13147\">Matryoshka Representation Learning</a> </b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d193f77-9d40-40c3-9018-f7d78d3a8f39",
   "metadata": {},
   "source": [
    "## æ€»ç»“ä¸€ä¸‹ RAG\n",
    "\n",
    "\n",
    "![](./rag-flow.jpg)\n",
    "\n",
    "\n",
    "å¦‚å›¾æ‰€ç¤ºï¼ŒRAGä¸»è¦ç”±ä¸¤ä¸ªéƒ¨åˆ†æ„æˆï¼š\n",
    "- **å»ºç«‹ç´¢å¼•**ï¼šé¦–å…ˆè¦æ¸…æ´—å’Œæå–åŸå§‹æ•°æ®ï¼Œå°† PDFã€Docxç­‰ä¸åŒæ ¼å¼çš„æ–‡ä»¶è§£æä¸ºçº¯æ–‡æœ¬æ•°æ®ï¼›ç„¶åå°†æ–‡æœ¬æ•°æ®åˆ†å‰²æˆæ›´å°çš„ç‰‡æ®µï¼ˆchunkï¼‰ï¼›æœ€åå°†è¿™äº›ç‰‡æ®µç»è¿‡åµŒå…¥æ¨¡å‹è½¬æ¢æˆå‘é‡æ•°æ®ï¼ˆæ­¤è¿‡ç¨‹å«åšembeddingï¼‰ï¼Œå¹¶å°†åŸå§‹è¯­æ–™å—å’ŒåµŒå…¥å‘é‡ä»¥é”®å€¼å¯¹å½¢å¼å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ä¸­ï¼Œä»¥ä¾¿è¿›è¡Œåç»­å¿«é€Ÿä¸”é¢‘ç¹çš„æœç´¢ã€‚è¿™å°±æ˜¯å»ºç«‹ç´¢å¼•çš„è¿‡ç¨‹ã€‚\n",
    "    - æ–‡æ¡£åŠ è½½ï¼Œå¹¶æŒ‰ä¸€å®šæ¡ä»¶**åˆ‡å‰²**æˆç‰‡æ®µ\n",
    "    - å°†åˆ‡å‰²åçš„æ–‡æ¡£è½¬åŒ–ä¸º embedding\n",
    "    - æŠŠ embedding å­˜å‚¨åˆ° embeddingStore ä¸­\n",
    "- **æ£€ç´¢ç”Ÿæˆ**ï¼šç³»ç»Ÿä¼šè·å–åˆ°ç”¨æˆ·è¾“å…¥ï¼Œéšåè®¡ç®—å‡ºç”¨æˆ·çš„é—®é¢˜ä¸å‘é‡æ•°æ®åº“ä¸­çš„æ–‡æ¡£å—ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œé€‰æ‹©ç›¸ä¼¼åº¦æœ€é«˜çš„Kä¸ªæ–‡æ¡£å—ï¼ˆKå€¼å¯ä»¥è‡ªå·±è®¾ç½®ï¼‰ä½œä¸ºå›ç­”å½“å‰é—®é¢˜çš„çŸ¥è¯†ã€‚çŸ¥è¯†ä¸é—®é¢˜ä¼šåˆå¹¶åˆ°æç¤ºè¯æ¨¡æ¿ä¸­æäº¤ç»™å¤§æ¨¡å‹ï¼Œå¤§æ¨¡å‹ç»™å‡ºå›å¤ã€‚è¿™å°±æ˜¯æ£€ç´¢ç”Ÿæˆçš„è¿‡ç¨‹ã€‚\n",
    "    - æŠŠç”¨æˆ· Query è½¬åŒ–ä¸º embeddingï¼ŒqueryEmbedding\n",
    "    - æ£€ç´¢æœ€ç›¸ä¼¼çš„å‡ ä¸ªæ–‡æ¡£ï¼Œæ‰¾åˆ°æœ€ç›¸ä¼¼çš„ K ä¸ª\n",
    "    - å–å› K ä¸ªæœ€ç›¸ä¼¼çš„æ–‡æ¡£æ–‡æœ¬\n",
    "    - æŠŠæ–‡æœ¬å‘é€ç»™å¤§æ¨¡å‹â€œåŒ…è£…â€ï¼Œç”Ÿæˆæœ€ç»ˆè¿”å›ç»™ç”¨æˆ·çš„æ–‡æœ¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29728ed4-30ca-485f-9615-ba6d1e41b407",
   "metadata": {},
   "source": [
    "## ä½œä¸šï¼š\n",
    "- 1. ç‹¬ç«‹å®Œæˆ RAG æµç¨‹çš„æ„å»ºä»£ç \n",
    "- 2. è¾“å…¥ä½ è‡ªå·±çš„æ–‡æ¡£ï¼Œè®©RAGæ¥å›ç­”ï¼Œçœ‹æ•ˆæœå¦‚ä½•ï¼Ÿ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
